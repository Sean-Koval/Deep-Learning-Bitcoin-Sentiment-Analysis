# Steps to setup the lambda and image to collect twitter data 

1) Create the .py file, Dockerfile, and requirments.txt file
2) Build the docker image locally to test
3) Run the docker image locally (make sure you have IAM role permissions attached to instance: edit the ~/.aws/config file)
4) Ping the endpoint to see if it worked

Commands:

# build command
docker build -t app:latest .

# run command
# only need this stuff for local (dont need to pass -v or -p)
docker run -p 9000:8080 -v $HOME/.aws:/root/.aws app:latest

# curl (for invoking)
curl -XPOST "http://localhost:9000/2015-03-31/functions/function/invocations" -d '{}'

# TESTED AND WORKING!


# Steps for Kinesis

1) Setup PUT kinesis stream (firehose)
2) Create a test lambda (that prints some bytes to stream)
3) Test using lambda in the UI
4) Look at the data stream of the kineses object
5) If you see data it worked! (should be able to move to testing storage in s3)
6) If this all works then the kinesis PUT stream should be all setup

# Setup Lambdas (general)

1) Create a test one in the UI and give permissions to write to the stream or to s3
2) test it
3) Abstract the lambda python code to Dockerfile
4) Test the dockerfile locally first (then move to a lambda fn)